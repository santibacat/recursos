{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Apuntes curso 2 tf DL.ai.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wzEYT6kjlunu","colab_type":"code","colab":{}},"source":["# usar version 2 de tensorflow en colab\n","!pip install tensorflow==2.0.0-alpha0\n","from __future__ import absolute_import, division, print_function"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95K6Sm2NaLZm","colab_type":"text"},"source":["# W2 Augmentation"]},{"cell_type":"code","metadata":{"id":"UuQLRitRl_In","colab_type":"code","colab":{}},"source":["import os # necesario para usar rutas\n","import zipfile # necesario para extraer archivos\n","import random\n","import tensorflow as tf\n","from shutil import copyfile\n","\n","# wget (para descargar archivos)\n","# forma: !wget #pagina# -O /tmp/destino\n","!wget \"http://ruta.com/archivo.zip\" -O \"/tmp/cats-and-dogs.zip\"\n","\n","# Lo extraemos\n","# Establecemos los directorios base con ayuda de\n","# os.path.join, os.listdir y len(os.listdir)\n","len(os.listdir(dir)) # esto muestra el numero de archivos en cada carpeta\n","\n","# Si hace falta, creamos las carpetas necesarias\n","os.mkdir('/tmp/carpeta')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0Zgv72rXcDb","colab_type":"text"},"source":["Si tenemos un pool de archivos, separamos entre archivos de entrenamiento y de validación:"]},{"cell_type":"code","metadata":{"id":"XfEKwf7bWk2q","colab_type":"code","colab":{}},"source":["def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n","    files = []\n","    for filename in os.listdir(SOURCE):\n","        file = SOURCE + filename\n","        if os.path.getsize(file) > 0:\n","            files.append(filename)\n","        else: # esto se hace para eliminar archivos erroneos sin tamaño\n","            print(filename + \" is zero length, so ignoring.\")\n","\n","    training_length = int(len(files) * SPLIT_SIZE)\n","    testing_length = int(len(files) - training_length)\n","    shuffled_set = random.sample(files, len(files))\n","    training_set = shuffled_set[0:training_length]\n","    testing_set = shuffled_set[:testing_length]\n","\n","    for filename in training_set:\n","        this_file = SOURCE + filename\n","        destination = TRAINING + filename\n","        copyfile(this_file, destination)\n","\n","    for filename in testing_set:\n","        this_file = SOURCE + filename\n","        destination = TESTING + filename\n","        copyfile(this_file, destination)\n","\n","### Otra forma de hacer esto sería (hecho por mi):\n","\n","def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n","  origin = os.listdir(SOURCE)\n","  num = len(origin)\n","  train_num = round(num*SPLIT_SIZE,0)\n","  test_num = round(num*(1-SPLIT_SIZE),0)\n","  shuffle = random.sample(origin, len(origin))\n","  train = shuffle[:int(train_num)]\n","  test = shuffle[int(train_num):]\n","  \n","  for i, image in enumerate(train):\n","    if os.path.getsize(os.path.join(SOURCE, image)) == 0:\n","      print('Image %s not copying. Zero filesize' % image)\n","    else:\n","      copyfile(os.path.join(SOURCE, image), os.path.join(TRAINING, image))\n","  \n","  for i, image in enumerate(test):\n","    if os.path.getsize(os.path.join(SOURCE, image)) == 0:\n","      print('Image %s not copying. Zero filesize' % image)\n","    else:\n","      copyfile(os.path.join(SOURCE, image), os.path.join(TESTING, image))\n","      \n","      \n","      \n","####\n","\n","CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n","TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n","TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n","DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n","TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n","TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n","\n","split_size = .9 # esto es el % que irá a cada carpeta\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n","\n","# Para comprobar que se ha hecho bien, mostramos los archivos de cada carpeta:\n","print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DhUVhElRY8Cf","colab_type":"code","colab":{}},"source":["# Comprobamos lss dimensiones de las imágenes\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","for i in range(10):\n","  img_dir = os.listdir(TRAINING_DOGS_DIR)\n","  img = load_img(os.path.join(TRAINING_DOGS_DIR, img_dir[i]))\n","  img_prueba = img_to_array(img)\n","  print(img_prueba.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwgORB7fXxK5","colab_type":"text"},"source":["Ahora creamos el modelo, mostramos summary y lo compilamos:"]},{"cell_type":"code","metadata":{"id":"rMjFcGO4X94D","colab_type":"code","colab":{}},"source":["from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(... RECUERDA input_shape=(150, 150, 3)),\n","    ...\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYItkcahYO6p","colab_type":"text"},"source":["Ahora añadimos el generador. Para AUMENTAR LOS DATOS:\n"]},{"cell_type":"code","metadata":{"id":"rbebOMuaYNzR","colab_type":"code","colab":{}},"source":["# https://keras.io/preprocessing/image/\n","TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","      rotation_range=40, # rotación\n","      width_shift_range=0.2, # movimiento del centro hacia up-down\n","      height_shift_range=0.2,\n","      shear_range=0.2, # deformación elástica\n","      zoom_range=0.2, # zoom de imagen\n","      horizontal_flip=True, # espejo\n","      fill_mode='nearest') # como rellenar pixeles vacios\n","train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n","                                                    batch_size=100,\n","                                                    class_mode='binary',\n","                                                    target_size=(150, 150))\n","\n","VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n","validation_datagen = ImageDataGenerator(rescale=1./255,\n","      #generalmente aqui no se pone nada)\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n","                                                              batch_size=100,\n","                                                              class_mode='binary',\n","                                                              target_size=(150, 150))\n","                                        \n","# No siempre hay que hacer augmentation, porque si le damos demasiada\n","# variabilidad puede que no salga bien (overfitting). A veces es mejor nada\n","# sobre todo si el dataset no es muy completo."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lrCezlYpUeo","colab_type":"text"},"source":["Mostrar gráficos con matplotlib de training y validation:"]},{"cell_type":"code","metadata":{"id":"HAoxCxNmpWyO","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","\n","# Y el resto como se hace siempre"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Lu_8gz7bvlm","colab_type":"text"},"source":["# W3 TRANSFER LEARNING"]},{"cell_type":"markdown","metadata":{"id":"1IjJKSVBbzsA","colab_type":"text"},"source":["Primero descargamos el modelo a cargar con o sin los pesos:"]},{"cell_type":"code","metadata":{"id":"O1JU1ym4peVX","colab_type":"code","colab":{}},"source":["# https://www.tensorflow.org/tutorials/images/transfer_learning\n","import os\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","\n","# CARGAR UN MODELO\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","pre_trained_model = InceptionV3(input_shape = (150, 150, 3), 'rgb obligatorio'\n","                                include_top = False, 'eliminar ultima capa'\n","                                weights = None) # o 'imagenet'\n","\n","# CARGAR PESOS DESCARGADOS\n","wget http://inception_v3_weights_tf_dim_ordering_notop.h5 -O /tmp/modelo\n","local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_notop.h5'\n","pre_trained_model.load_weights(local_weights_file)\n","  \n","# pre_trained_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-a_JOcMrcxYs","colab_type":"text"},"source":["Obtener nombres para crear el modelo completo:"]},{"cell_type":"code","metadata":{"id":"Qi5_pekYczZ7","colab_type":"code","colab":{}},"source":["# OBTENER NOMBRE DE CAPA PARA \n","last_layer = pre_trained_model.get_layer('mixed7')\n","# Debemos usar el nombre que veamos en el summary para la ultima capa\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wj-jLKxfc9BO","colab_type":"text"},"source":["Para crear nuestro modelo completo, le añadimos las capas finales que queramos, y LO COMPILAMOS:"]},{"cell_type":"code","metadata":{"id":"lKmwYurWdB1R","colab_type":"code","colab":{}},"source":["# Hay que hacerlo siguiendo la functional API\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","x = layers.Flatten()(last_output)\n","x = layers.Dense(1024, activation='relu')(x)\n","x = layers.Dropout(0.2)(x) # ESTO AÑADE REGULARIZACIÓN, evita overfitting                 \n","x = layers.Dense  (1, activation='sigmoid')(x)           \n","\n","model = Model(pre_trained_model.input, x) # Model(inputs =, outputs =)\n","\n","model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'binary_crossentropy', \n","              metrics = ['acc'])\n","\n","\n","# Otra forma de hacer el modelo con la API secuencial:\n","model = tf.keras.Sequential([\n","  pre_trained_model,\n","  keras.layers.GlobalAveragePooling2D(),\n","  keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ONvIG9_XfYog","colab_type":"text"},"source":["Toquetear el modelo y hacerlo entrenable:"]},{"cell_type":"code","metadata":{"id":"gZZiaTvJfaPB","colab_type":"code","colab":{}},"source":["# PARA HACERLO ENTRENABLE (TODAS LAS CAPAS)\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","  \n","# Otra forma: pre_trained_model.trainable = False\n","\n","# VER VARIABLES ENTRENABLES:\n","len(pre_trained_model.trainable_variables)\n","\n","# ENTRENAR SOLO CIERTAS CAPAS\n","# Vemos numero total de capas\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Elegimos una capa a partir de la que entrenar (o la buscamos)\n","fine_tune_at = 100 # a partir de la capa 100\n","\n","# Congelamos todas las capas anteriores\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False\n","\n","# IMAGEN DEL MOVELO\n","%matplotlib inline\n","from keras.utils import plot_model\n","plot_model(pre_trained_model, to_file='model.png')\n","\n","from IPython.display import Image \n","Image(filename='model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IfEiRiP_-3GD","colab_type":"text"},"source":["# W4 MULTICLASS Clasification"]},{"cell_type":"code","metadata":{"id":"T0f68_Jk-6XW","colab_type":"code","colab":{}},"source":["# En vez de crear un subdirectorio en training-testing creamos 'x' directorios\n","# y lo mostramos\n","%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","pic_index = 2\n","\n","next_rock = [os.path.join(rock_dir, fname) \n","                for fname in rock_files[pic_index-2:pic_index]]\n","next_paper = [os.path.join(paper_dir, fname) \n","                for fname in paper_files[pic_index-2:pic_index]]\n","next_scissors = [os.path.join(scissors_dir, fname) \n","                for fname in scissors_files[pic_index-2:pic_index]]\n","\n","for i, img_path in enumerate(next_rock+next_paper+next_scissors):\n","  #print(img_path)\n","  img = mpimg.imread(img_path)\n","  plt.imshow(img)\n","  plt.axis('Off')\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7U9DHrzi_I1z","colab_type":"text"},"source":["Ahora a la hora de crear el modelo tan solo hay que cambiar:"]},{"cell_type":"code","metadata":{"id":"vs4qy75q_LXk","colab_type":"code","colab":{}},"source":["train_generator = training_datagen.flow_from_directory(\n","\t...\n","\tclass_mode='categorical')\n","\n","model = tf.keras.models.Sequential([\n","   ...\n","   tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","# Cuando ya tenemos el modelo entrenado lo podemos guardar\n","model.save(\"saved_model.h5\")"],"execution_count":0,"outputs":[]}]}