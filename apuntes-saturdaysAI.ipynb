{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AISaturdays.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNW0uLMCP5GmmrFhhlKMmdO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wr_NREMDJ-TU","colab_type":"code","outputId":"9a5cf989-0336-4d3f-ec7a-d636222bfcb4","executionInfo":{"status":"ok","timestamp":1581154855135,"user_tz":-60,"elapsed":1090,"user":{"displayName":"Santi Bacat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA4y-9VrWAAh_CxZbKozOMT9SBBhO024HQAJHn0g4g=s64","userId":"17646288971276982559"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Comprobar que usamos Python 3\n","import sys\n","print(sys.version)\n","\n","# Operadores\n","print(\"División entera:\",      5 // 2)\n","print(\"Resto de la división:\", 5 % 2)\n","print(\"Exponente:\",            5 ** 2)\n","\n","# Strings\n","s1 = 'estoy'       # Pueden ser comillas simples\n","s2 = \"aprendiendo\" # O comillas dobles\n","print(s1, s2)\n","print(s1+s2) # es distinto (sin espacio)\n","\n","# Listas\n","mi_lista = [\"a\", \"b\", \"c\", \"d\"]\n","mi_lista.pop() #sirve para eliminar el ultimo valor de una lista\n","print(mi_lista)\n","\n","# Diccionarios\n","animal_sounds = {\n","    'dog': 'bark',\n","    'cat': 'meow',\n","    'pig': 'oink'\n","}\n","\n","for animal, sound in animal_sounds.items():\n","    print(\"The \" + animal + \" says \" + sound + \"!\")\n","\n","for animal, sound in enumerate(animal_sounds): #esto solo enumera indices + key\n","    print(animal, sound)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3.6.9 (default, Nov  7 2019, 10:44:02) \n","[GCC 8.3.0]\n","División entera: 2\n","Resto de la división: 1\n","Exponente: 25\n","estoy aprendiendo\n","estoyaprendiendo\n","['a', 'b', 'c']\n","The dog says bark!\n","The cat says meow!\n","The pig says oink!\n","0 dog\n","1 cat\n","2 pig\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6dspZhQ3KzYW","colab_type":"text"},"source":["# **DIA 1**"]},{"cell_type":"markdown","metadata":{"id":"zpCloXN3LZ9r","colab_type":"text"},"source":["## Pandas"]},{"cell_type":"code","metadata":{"id":"21i2OazQK3pO","colab_type":"code","colab":{}},"source":["import pandas as pd\n","pd.set_option(\"display.precision\", 2)      # Display 2 decimals\n","pd.set_option('display.max_columns', 1000) # Display all variables\n","\n","df.shape\n","df.columns\n","df.info() #importante crear una tabla en MD con las variables y su descripción\n","df.describe() # solo numéricas\n","df.describe(include=['object', 'bool']) # solo categoricas\n","\n","# Tipos de variables\n","def tipos_variables(df):\n","\"\"\" Python guarda categoricas como objetos, las de tiempo como tiempo, el resto como numericas \"\"\"\n","    # Tipos variables: object = categoricas; bool = booleanas; datetime64 = tiempo\n","    cat  = df.select_dtypes(include=[object]).columns\n","    num  = df.select_dtypes(exclude=[object, 'datetime64','timedelta64']).columns\n","    time = df.select_dtypes(include=['datetime64']).columns\n","    print(\"\\nNumerical features:\\n\", len(num), num.values)\n","    print(\"\\nCategorical features:\\n\", len(cat), cat.values)\n","    print(\"\\nDate/time features:\\n\", len(time), time.values)\n","    return cat, num, time\n","\n","tipos_variables(df)\n","\n","# Para variables categoricas\n","df.value_counts() # es countS(), no count\n","df.value_counts(normalize_True) # cuenta porcentajes\n","\n","for var in cat.values:\n","    print(df[var].value_counts(), \"\\n\")\n","\n","pd.crosstab(df['1'], df['2']) # tabla de contingencia\n","pd.crosstab(df['1'], df['2'], margins = True) # con margenes\n","pd.crosstab(df['1'], df['2'], normalize = True) # con %\n","df.groupby(['category', 'name']).mean()\n","\n","df[\"variable\"].mean() # va con parentesis()\n","\n","# Para variables numericas y categoricas\n","df.pivot_table([\"1\", '2', '3'], ['x1'. 'x2'], aggfunc='mean') # te hace una tabla cruzada en funcion a varios valores\n","\n","# Para hacerlo directo (Pandas-profiling)\n","from pandas_profiling import ProfileReport\n","profile = ProfileReport(df)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNTAuAk0smgg","colab_type":"text"},"source":["# <center> Summary\n","- The data table is a Pandas **dataframe**\n","- The data column is a Pandas **series**\n","- We can obtain information of the **dataset**:\n","  - 10 top rows: `df.head(10)`\n","  - Number of rows & variables: `df.shape`\n","  - Names of variables: `df.columns`\n","  - Types of variables: `df.info()`\n","  - Stats of numerical variables: `df.describe()`\n","  - Stats of numerical variables: `df.describe(include=['object', 'bool'])`\n","- Information of **numerical variables**:\n","  - Minimum `df.num_var.min()`\n","  - Maximun `df.num_var.max()`\n","  - Mean `df.num_var.mean()`\n","  - Median `df.num_var.median()`\n","  - Std `df.variable.std()`\n","- Information of **categorial variables**:\n","  - Unique values (count): `df.cat_var.value_counts()`\n","  - Unique values (percen): `df.cat_var.value_counts(normalize=True)`\n","  - 2 categorial vars (count): `pd.crosstab(df.cat_var1, df.cat_var2, margins=True)`\n","  - 2 categorial vars (percen): `pd.crosstab(df.cat_var1, df.cat_var2, margins=True, normalize=True)`\n","- Information of **numerical & categorial variables**:\n","  - Pivot table: `df.pivot_table([num_var1, num_var2, ...], [cat_var1, cat_var2], aggfunc='mean')`\n","- **Fitering rows**:\n","  - One filter: `df[ condition ]`\n","  - Multiple filters: `df[ (condition1) & (condition2)]`"]},{"cell_type":"markdown","metadata":{"id":"40w3UjRfTujL","colab_type":"text"},"source":["## Seaborn"]},{"cell_type":"code","metadata":{"id":"k3Xf6HtCTwNZ","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","# We will use the Seaborn library\n","import seaborn as sns\n","sns.set()\n","%config InlineBackend.figure_format = 'svg' # Mejor calidad y nitidez\n","\n","# TIPOS VISUALIZACIÓN UNIVARIANTE\n","sns.countplot(variable) # contar valores\n","df.hist # histograma\n","df.plot(kind=\"density\") # densidad\n","sns.distplot(df) # gráfico de distribución\n","sns.boxplot(data=df) # boxplot\n","sns.violinplot(data=df) #violin plot\n","\n","sns.kdeplot() # kernel density estimate (rayas con circulos laberinticos)\n","sns.regplot() # muestra datos (como puntos) + una regresión lineal de los mismos\n","sns.regplot(order=2) # regresión de segundo orden (cuadratica x ej)\n","\n","# Para hacer dos en una imagen\n","_, axes = plt.subplots(1, 2, sharey=True, figsize=(6, 4))\n","sns.boxplot(data=df['Total intl calls'], ax=axes[0]) # igual para el otro\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"doy_b8Zjk0w-","colab_type":"code","colab":{}},"source":["# Variables numéricas\n","def plot_num(variable, title=\"\", min=False, max=False, zeros=True, size=(16,4)):\n","    if not zeros:\n","        variable=variable[variable!=0]\n","        title += \" (no zeros)\"\n","    if min:\n","        variable = variable[variable >= min]\n","        title += \" (min: \"+str(min)+\")\"\n","    if max:\n","        variable = variable[variable <= max]\n","        title += \" (max: \"+str(max)+\")\"\n","    fig, ax = plt.subplots(figsize=size)\n","    ax.set_title(title, fontsize=20)\n","    ax2 = ax.twinx()\n","    sns.violinplot(variable, cut=0, palette=\"Set3\", inner=\"box\", ax=ax)\n","    sns.scatterplot(variable, y=variable.index, color=\"grey\", linewidth=0, s=20, alpha=.3, ax=ax2).invert_yaxis()\n","    \n","def plot_num2(variable, title=\"\", min=False, max=False, zeros=True, size=(16,4)):\n","    if not zeros:\n","        variable=variable[variable!=0]\n","        title += \" (no zeros)\"\n","    if min:\n","        variable = variable[variable >= min]\n","        title += \" (min: \"+str(min)+\")\"\n","    if max:\n","        variable = variable[variable <= max]\n","        title += \" (max: \"+str(max)+\")\"\n","    plt.figure(figsize=size)\n","    sns.violinplot(variable, cut=0, palette=\"Set3\", inner=\"quart\" )\n","    sns.stripplot(variable, color=\"grey\", alpha=.5).set_title(title, fontsize=20);\n","\n","# Variables ordinales\n","def plot_ord(variable, title=\"\", min=False, max=False, zeros=True, size=(16,4)):\n","    if not zeros:\n","        variable=variable[variable!=0]\n","        title += \" (no zeros)\"\n","    if min:\n","        variable = variable[variable >= min]\n","        title += \" (min: \"+str(min)+\")\"\n","    if max:\n","        variable = variable[variable <= max]\n","        title += \" (max: \"+str(max)+\")\"\n","    plt.figure(figsize=size)\n","    sns.countplot(variable, color='royalblue').set_title(title, fontsize=20);\n","    \n","# Variables categoricas\n","def plot_cat(variable, title=\"\", top=False, normalize=False, dropna=False, size=(16,4)):\n","    plt.figure(figsize=size)\n","    cats = variable.value_counts(normalize=normalize, dropna=dropna)\n","    if top:\n","        cats = cats[:top]\n","        title += \" (top \"+str(top)+\")\"\n","    sns.barplot(x=cats, y=cats.index).set_title(title, fontsize=20);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcAUVvq5laYv","colab_type":"code","colab":{}},"source":["# Matriz de correlaciones (.corr)\n","corr_matrix = df[numerical].corr()\n","sns.heatmap(corr_matrix)\n","\n","# si quieres añadir tan solo media matriz (no mostrar dos veces la misma correlación)\n","mask = np.triu(np.ones_like(corr, dtype=np.bool))\n","sns.heatmap(corr, annot=True, mask=mask, center=0, vmin=-1, vmax=1, linewidths=1, square=True);\n","\n","# Variables correlacionadas con una en concreto (.corrwith)\n","target_corrlations = df_train.corrwith(df_train['Variable']).sort_values(ascending=False)\n","sns.barplot(target_corrlations, target_corrlations.index);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F2_tFJw59JF8","colab":{}},"source":["# Para hacer pares de variables\n","sns.pairplot(df)\n","sns.pairplot(df, corner=True)\n","    # si solo queremos mostrar la parte de abajo del triángulo\n","sns.pairplot(df, hue=\"salary\", dropna=True) \n","    # pairplot en función de la variable a precedir\n","sns.jointplot(x, y, data=df) #grafico conjunto con histograma en bordes\n","sns.lmplot() #facetgrid plot (puntos en funcion de densidad lineal)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vB7hxUC9MHn","colab_type":"code","colab":{}},"source":["# Pairgrid (pares de variables)\n","grid = sns.PairGrid(data=df, vars=['Age', 'Fare', \"Pclass\"], hue=\"Survived\", height=4)\n","\n","# map_upper = parte de arriba del triangulo\n","# map_lower = parte de abajo\n","# map_diag = diagonal\n","# map_offdiag = fuera de diagonal\n","# hue = colorear distinto en función a categorías de una variable\n","# vars = elegir las variables que queremos dentro de un df\n","# tambien podemos elegir que queremos en cada eje con x_vars/y_vars\n","#g = sns.PairGrid(iris,\n","#                 x_vars=[\"sepal_length\", \"sepal_width\"],\n","#                 y_vars=[\"petal_length\", \"petal_width\"])\n","\n","grid = grid.map_upper(sns.kdeplot) # UPPER TRIANGLE: sns.regplot || sns.kdeplot || sns.hexbin || sns.heatmap\n","grid = grid.map_diag(plt.hist)     # DIAGONAL:       plt.hist    || sns.kdeplot, lw=2\n","grid = grid.map_lower(sns.regplot) # LOWER TRIANGLE: sns.regplot || sns.kdeplot\n","grid = grid.add_legend()\n","grid;"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uiKDUmumLQB","colab_type":"code","colab":{}},"source":["# Missing values\n","def plot_missings(df):\n","    missing = df.isnull().sum()\n","    missing = missing/df.isnull().count()*100\n","    missing = missing[missing > 0]\n","    missing.sort_values(ascending=False, inplace=True)\n","    missing.plot.bar()\n","\n","def get_missings(df):\n","    total = df.isnull().sum().sort_values(ascending=False)\n","    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n","    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n","    return missing_data\n","    \n","plot_missings(df)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZppk-HWu55h","colab_type":"text"},"source":["En 2.1 y 3.2 al final hay un apartado de reducción de la dimensionalidad:\n","\n","* PCA\n","* tSNE\n","* Survival plots"]},{"cell_type":"code","metadata":{"id":"LXJ255AdnGQi","colab_type":"code","colab":{}},"source":["def plot_multidimensional(X, y):\n","    \n","    x_pca  = PCA(n_components=2).fit_transform(X)  # Compute PCA\n","    x_tsne = TSNE(random_state=0).fit_transform(X) # Compute TSNE\n","    \n","    df = pd.DataFrame({'pca1': x_pca[:, 0],  'pca2': x_pca[:, 1],\n","                      'tsne1': x_tsne[:, 0], 'tsne2': x_tsne[:, 1],\n","                      \"y\": y})\n","    \n","    brush = alt.selection(type='interval', resolve='global')\n","    \n","    scatter = alt.Chart(df).mark_circle().encode(\n","        color=alt.condition(brush, 'y:N', alt.ColorValue('lightgray')),\n","    ).add_selection(\n","        brush\n","    ).properties(\n","        width=250,\n","        height=250\n","    )\n","    \n","    bars = alt.Chart(df).mark_bar().encode(\n","        x='y:N', \n","        y='count(y):Q',\n","        color='y:N',\n","    ).transform_filter(\n","        brush\n","    ).properties(\n","        width=250,\n","        height=250\n","    )\n","\n","    return scatter.encode(x='pca1', y='pca2') | scatter.encode(x='tsne1', y='tsne2') | bars\n","\n","plot_multidimensional(X, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHNvSYKyQk9B","colab_type":"code","colab":{}},"source":["# tSNE (procede de 2.8)\n","from sklearn.manifold import TSNE\n","import altair as alt\n","\n","model = TSNE(n_components=2, random_state=0, perplexity=40, n_jobs=-1)\n","X = df[tsne_feats].fillna(0.).values\n","tsne = model.fit_transform(X)\n","\n","df['tsne1']   = tsne[:,0]\n","df['tsne2']   = tsne[:,1]\n","\n","\n","alt.Chart(df).mark_circle().encode(\n","    x='tsne1:Q', # Si es numerica se pone Q\n","    y='tsne2:Q',\n","    color='Survived:N', # si es categórica se pone N\n","    tooltip=['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n","    # es para que cuando pones cursor encima te diga características de éstas\n",").properties(\n","    width=400,\n","    height=400\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S5n-eF_6jD1w","colab_type":"text"},"source":["# DIA 2"]},{"cell_type":"markdown","metadata":{"id":"6xG-sb8ZjHP-","colab_type":"text"},"source":["## Preprocesado de datos"]},{"cell_type":"code","metadata":{"id":"OucON1N9jGOn","colab_type":"code","colab":{}},"source":["# Eliminar NA\n","df = df.dropna(axis='rows')\n","\n","# Convertir variables categóricas\n","cat  = df.select_dtypes(include=[object]).columns\n","df[cat] = df[cat].apply(OrdinalEncoder().fit_transform)\n","\n","# Mapear variables categóricas\n","df[\"Survived\"] = df[\"Survived\"].map({0: \"Died\", 1: \"Survived\"})\n","\n","# Aplicar pipeline segun las columnas\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler',  StandardScaler())\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","    ('onehot',  OneHotEncoder(handle_unknown='ignore'))])\n","\n","binary_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('label',   OneHotEncoder(drop='first'))])\n","\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num', numeric_transformer,     numeric_features),\n","    ('cat', categorical_transformer, categorical_features),\n","    ('bin', binary_transformer,      binary_features)\n","])\n","\n","transformed_data = preprocessor.fit_transform(df)\n","# * si queremos ver los nombres de las variables transformadas, ver le siguiente*\n","\n","\n","\n","# Train-test split con estratificación en función de y\n","x_train, x_valid, y_train, y_valid = train_test_split(x, y,\n","                                                      test_size=0.2,\n","                                                      stratify=df[\"y\"], \n","                                                      random_state=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfnUwpOdcwqE","colab_type":"code","colab":{}},"source":["# Cogido de 2.5 Logistic Regression\n","def get_transformer_feature_names(columnTransformer):\n","    # función para coger los nombres de las variables categoricas (onehot)\n","    output_features = []\n","\n","    for name, pipe, features in columnTransformer.transformers_:\n","        if name!='remainder':\n","            for i in pipe:\n","                trans_features = []\n","                if hasattr(i,'categories_'):\n","                    trans_features.extend(i.get_feature_names(features))\n","                else:\n","                    trans_features = features\n","            output_features.extend(trans_features)\n","\n","    return output_features\n","\n","var_names = get_transformer_feature_names(preprocessor)\n","df_prepro = pd.DataFrame(transformed_data, columns=var_names)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lSTB05WsqDDt","colab_type":"text"},"source":["## Workflow modelos"]},{"cell_type":"code","metadata":{"id":"6jm4NzRjqCOc","colab_type":"code","colab":{}},"source":["# Crear modelo\n","model = DecisionTreeClassifier()\n","\n","# Entrenar modelo\n","model.fit(x_train, y_train)\n","\n","# Predecir usando modelo entrenado\n","preds = model.predict(x_valid)\n","\n","# Métricas y comprobación\n","print(\"Accuracy (Caution):\", accuracy_score(y_valid, preds)*100)\n","print(\"Balanced accuracy: \", balanced_accuracy_score(y_valid, preds)*100)\n","plot_confusion_matrix(model, x_valid, y_valid, cmap=plt.cm.Blues, \n","                      display_labels=[\"Label 1\",\"Label 2\"], normalize=\"pred\")\n","\n","# Importancia de características\n","fi = pd.DataFrame({\n","      'feature':     x.columns,\n","      'importance':  model.feature_importances_ # posee el % de importancia\n","     }).sort_values('importance', ascending=False).reset_index(drop=True)\n","\n","sns.barplot(x=fi.importance, y=fi.feature).set_title(\"Feature Importance\");"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8UQhZVSYAzW","colab_type":"code","colab":{}},"source":["# Métodos avanzados\n","\n","# Permutation Feature Importance\n","# muestra la importancia de cada variable haciendo como si la \"permutaramos\"\n","# y viendo como aumenta el error\n","pfi = permutation_importance(model, x_valid, y_valid, n_repeats=10, random_state=0, n_jobs=-1)\n","sorted_idx = pfi.importances_mean.argsort()[::-1] \n","# saca la media de las importancias y las ordena al reves (de mayor a menor)\n","pfi_df = pd.DataFrame(data=pfi.importances[sorted_idx].T, columns=x_valid.columns[sorted_idx])\n","sns.barplot(data=pfi_df, orient=\"h\").set_title(\"Permutation Feature Importance (validation set)\",  fontsize=20);\n","\n","# Partial dependence plot\n","# muestra la dependencia de cada variable en función de y\n","fig, ax = plt.subplots(figsize=(16, 4))\n","plot_partial_dependence(estimator=model,\n","                        X=x_train,\n","                        features=[\"education-num\", \"age\", (\"age\", \"education-num\")],\n","                        grid_resolution=10,\n","                        ax=ax,\n","                        n_jobs=-1\n","                       );\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nl2pn_j3TdY_","colab_type":"code","colab":{}},"source":["# Tipos de modelos:\n","models = [\n","    ('LinealRegression',    LinealRegression()),\n","    ('Logistic Regression', LogisticRegression(n_jobs=-1)),\n","    ('Decision Tree',       DecisionTreeClassifier()),\n","    ('Extra Trees',         ExtraTreesClassifier(n_jobs=-1)),\n","    ('Random Forest',       RandomForestClassifier(n_jobs=-1)),\n","    ('Gradient Boosting',   GradientBoostingClassifier()),\n","    ('XGBoost',             XGBClassifier(n_estimators=250))\n","]\n","\n","outcome = []\n","Modelnames = []\n","\n","# esto no guarda los modelos, es solo para ver cual es mejor\n","for name, model in models:\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n","    cv_r = cross_val_score(model, x, y, cv=skf, scoring='accuracy')\n","    outcome.append(cv_r)\n","    Modelnames.append(name)\n","    print(\"%s: %.2f%% (%.2f%%)\" % (name, cv_r.mean()*100, cv_r.std()*100))\n","\n","sns.boxplot(Modelnames, outcome)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eki8Op7ZdGFT","colab_type":"code","colab":{}},"source":["# Metricas en modelos de regresión logistica\n","y_pred       = model.predict(x_val)\n","y_pred_proba = model.predict_proba(x_val)[:, 1]\n","results      = pd.DataFrame({\"Predicted\": y_pred_proba, \"Real\": y_val})\n","\n","print(\"Accuracy:         \", accuracy_score(y_val, y_pred)*100)\n","print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred)*100)\n","print(\"Area Under Curve: \", roc_auc_score(y_val, y_pred))\n","print(\"Log loss:         \", log_loss(y_val, y_pred))\n","\n","\n","f, axes = plt.subplots(2, 3, figsize=(12, 8))\n","plot_confusion_matrix(      model, x_val, y_val, ax=axes[0, 0], cmap=plt.cm.Blues, normalize=\"true\")\n","plot_roc_curve(             model, x_val, y_val, ax=axes[0, 1])\n","plot_precision_recall_curve(model, x_val, y_val, ax=axes[0, 2])\n","sns.boxplot(  x=\"Real\", y=\"Predicted\", data=results, ax=axes[1, 0])\n","sns.swarmplot(x=\"Real\", y=\"Predicted\", data=results, ax=axes[1, 1])\n","plt.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMWuUxadgdCF","colab_type":"code","colab":{}},"source":["# Coeficientes (riesgo relativo por variable)\n","pd.DataFrame({'Variable': var_names,'Coeficiente': model.coef_[0]})\n","sns.barplot(x=model.coef_[0], y=var_names)\n","# var_names procede de preprocesado (transformación de variables categóricas)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9JsKRGlWvY_A","colab_type":"text"},"source":["### Modelos de regresión"]},{"cell_type":"markdown","metadata":{"id":"KBB_PNxPytbw","colab_type":"text"},"source":["#### Regresión lineal"]},{"cell_type":"markdown","metadata":{"id":"ds-al8K7vcT_","colab_type":"text"},"source":["Hemos de tener en cuenta:\n","\n","* Que se usan MSE y coeficiente de determinación (R-squared o R2)\n","* Plots de y vs ypred, así como residuo (ypred-y) vs ypred\n","* Podemos convertir las variables (aplicarle logaritmos, etc)\n","    * `targets = np.log(targets)`\n","\n","* En regresión lineal los coeficientes son insensibles a la escala\n","* En tecnicas regularizadas si que hay que estandarizar los predictores"]},{"cell_type":"code","metadata":{"id":"j3KoRzuWvPkj","colab_type":"code","colab":{}},"source":["# The mean squared error\n","print('Mean squared error: %.2f' % metrics.mean_squared_error(y_test, y_pred))\n","# The coefficient of determination: 1 is perfect prediction\n","print('Coefficient of determination (R2): %.2f' % metrics.r2_score(y_test, y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UjU6hSlkyQcI","colab_type":"code","colab":{}},"source":["# Plot y - ypred\n","x = np.linspace(0, 800000, 800001)\n","plt.scatter(x = y_test, y = y_pred)\n","plt.plot(x, x, 'r-')\n","\n","plt.xlabel('Precio real')\n","plt.ylabel('Precio predicho')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZFLOBFLyT0q","colab_type":"code","colab":{}},"source":["# Plot residuo - ypred\n","plt.scatter(x = y_pred, y = y_test-y_pred)\n","plt.axhline(y=0, linewidth=4, color='r')\n","\n","plt.xlabel('Precio predicho')\n","plt.ylabel('Residuo')\n","\n","plt.show()\n","\n","sns.distplot(y_pred-y_test);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-OwI2Ge3jZiF","colab_type":"text"},"source":["* Regresión lineal = sin regularizar\n","* Regresión ridge y lasso = regularizadas\n","  * hiperparámetro lambda"]},{"cell_type":"code","metadata":{"id":"6VJ7FfG9yhrb","colab_type":"code","colab":{}},"source":["# Crear un modelo lineal con statsmodel\n","import statsmodels.api as sm\n","\n","model1 = sm.OLS(endog = y_train,exog = X_train).fit()\n","print(model1.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BR7Zm4XqmWyk","colab_type":"text"},"source":["## No supervisado"]},{"cell_type":"markdown","metadata":{"id":"hLrOo5rxnKrs","colab_type":"text"},"source":["Siempre se hace lo mismo:\n","\n","1. Se crea el algoritmo\n","2. Se le hace .fit\n","3. Se guardan las labels_ que se han obtenido de cada punto\n","4. Se hace plot"]},{"cell_type":"code","metadata":{"id":"4TiQqKX5mX-N","colab_type":"code","colab":{}},"source":["# kmeans (busca centroides de los grupos)\n","from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=4, random_state=0).fit(sintetic[[\"x\", \"y\"]])\n","\n","# guarda los datos (labels de cada punto y los centros)\n","sintetic[\"kmeans4\"] = kmeans.labels_\n","centers = pd.DataFrame(kmeans.cluster_centers_, columns=[\"x\", \"y\"])\n","\n","# Plot\n","points  = alt.Chart(sintetic).mark_circle().encode(x='x', y='y', color=\"kmeans4:N\")\n","centers = alt.Chart(centers).mark_circle(color='black', size=100).encode(x='x', y='y')\n","points + centers\n","\n","\n","# DBSCAN (busca densidades contiguas)\n","from sklearn.cluster import DBSCAN\n","dbscan  = DBSCAN(eps=1).fit(sintetic[[\"x\", \"y\"]])\n","sintetic[\"dbscan\"] = dbscan.labels_\n","alt.Chart(sintetic).mark_circle().encode(x='x', y='y', color=\"dbscan:N\")\n","\n","# OPTICS (busca densidades-variables contiguas)\n","from sklearn.cluster import OPTICS\n","optics = OPTICS(min_samples=50, xi=.05, min_cluster_size=.05).fit(sintetic[[\"x\", \"y\"]])\n","sintetic[\"optics\"] = optics.labels_\n","alt.Chart(sintetic).mark_circle().encode(x='x', y='y', color=\"optics:N\")\n","\n","# CLUSTERING Aglomerativo (de abajo a arriba)\n","from sklearn.cluster import AgglomerativeClustering\n","hierarchical = AgglomerativeClustering().fit(sintetic[[\"x\", \"y\"]])\n","sintetic[\"hierarchical\"] = hierarchical.labels_\n","alt.Chart(sintetic).mark_circle().encode(x='x', y='y', color=\"hierarchical:N\")\n","\n","# Clustering jerárquico (de arriba a abajo)\n","from scipy.cluster import hierarchy\n","Z = hierarchy.linkage(sintetic[[\"x\", \"y\"]], 'ward')\n","dn = hierarchy.dendrogram(Z)"],"execution_count":0,"outputs":[]}]}