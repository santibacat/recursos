
# COMPETICIONES - KAGGLE

## APUNTES JOSE JAVIER


- https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205 


- Consejos
  - Guardar cada paso, con puntuación interna y kaggle
  - Métrica positiva o negativa
  - Hacer primer modelo básico y subirlo
  - Lightgbm es muy rápido con buenos resultados
  - Búsqueda característica mágica
  - Revisar continuamente foros, notebooks
  - Stacking, variedad modelos, modelo final simple
  - Seguir tu propia línea
  - Probar con varias semillas
  - No obsesionarse con public score
  - Buscar ideas en competiciones anteriores
  - Para elegir los dos resultados finales: mejor interno mejor public score


- Charla José Antonio Guerrero
  - [Cómo llegar a número 1 en Kaggle](https://youtu.be/hJL9jXe1FlI) (1/2)
  - [Response stacking](https://youtu.be/HdCk6vGufJc) (2/2)


### LightGBM vs XGBoost
- https://pyligent.github.io/2019-08-20-lightGBM_XGBoost/
- https://towardsdatascience.com/lightgbm-vs-xgboost-which-algorithm-win-the-race-1ff7dd4917d
- https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db
